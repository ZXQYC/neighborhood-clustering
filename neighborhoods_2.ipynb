{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "filled-floating",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "import pickle\n",
    "import importlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import scipy.spatial\n",
    "import sklearn\n",
    "from sklearn import preprocessing,decomposition,linear_model\n",
    "\n",
    "import progress\n",
    "import jsdump\n",
    "import latlon\n",
    "import polygons\n",
    "import polygongraph\n",
    "import footprint_kml_poly_extractor\n",
    "import FloatColorMapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "given-potato",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the (longitude, latitude) center for for the distance approximation calculator\n",
    "# use a point near the center of the place you're at\n",
    "# the current coordinates are for Champaign, IL\n",
    "CENTER_X = -88.2434\n",
    "CENTER_Y = 40.1164\n",
    "\n",
    "latlon.set_center(CENTER_X,CENTER_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "future-professional",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of MultiPolygon objects representing house footprints\n",
    "house_polys = footprint_kml_poly_extractor.extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "matched-contribution",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "address_found          1.000000\n",
       "taxes_found            1.000000\n",
       "tax_year            2019.000000\n",
       "tax_amount          6970.514557\n",
       "market_value      235439.533823\n",
       "land_value         55474.155970\n",
       "building_value    179965.377853\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read tax data that was extracted from PropertyShark\n",
    "tax_frame = pd.read_csv('PropertyShark/tax_all.csv')\n",
    "# get averages out of places with taxes found\n",
    "tax_average = tax_frame[tax_frame['taxes_found']==1].mean(0)\n",
    "tax_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "utility-vault",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xanthi/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3155: DtypeWarning: Columns (17,28,31,32,35) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45674, 53)\n"
     ]
    }
   ],
   "source": [
    "# read champaign-addresses.csv\n",
    "addr_frame = pd.read_csv('champaign-addresses.csv')\n",
    "# get rid of inactive and non-residential addresses\n",
    "addr_frame = addr_frame[list(addr_frame['Status']=='Active')]\n",
    "addr_frame = addr_frame[list(addr_frame['Residential']=='Y')]\n",
    "addr_frame.reset_index(drop=True, inplace=True)\n",
    "# create 'address' column to merge with tax_frame\n",
    "addr_frame['address'] = addr_frame['StreetAddress']\n",
    "\n",
    "# merge with tax_frame\n",
    "addr_frame = addr_frame.merge(tax_frame,on='address')\n",
    "print(addr_frame.shape)\n",
    "\n",
    "# create addr_pts: list of x,y coordinates for the addresses\n",
    "addr_pts = addr_frame[['X','Y']].values\n",
    "\n",
    "# save addr_frame\n",
    "addr_frame.to_csv('addresses_with_tax.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "comfortable-bathroom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START (45674 total, updates every 10000)\n",
      "10000 / 45674 = 0.219 (2.20 s)\n",
      "20000 / 45674 = 0.438 (5.23 s)\n",
      "30000 / 45674 = 0.657 (8.01 s)\n",
      "40000 / 45674 = 0.876 (10.30 s)\n",
      "45674 / 45674 = 1.000 (11.31 s)\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(polygons)\n",
    "putted_indices = polygons.put_points_into_polys(addr_pts, house_polys, updateEvery=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "monthly-maker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating houses...\n",
      "Putting addresses into houses...\n",
      "START (45674 total, updates every 5000)\n",
      "5000 / 45674 = 0.109 (8.03 s)\n",
      "10000 / 45674 = 0.219 (13.74 s)\n",
      "15000 / 45674 = 0.328 (20.70 s)\n",
      "20000 / 45674 = 0.438 (26.94 s)\n",
      "25000 / 45674 = 0.547 (33.83 s)\n",
      "30000 / 45674 = 0.657 (43.47 s)\n",
      "35000 / 45674 = 0.766 (47.04 s)\n",
      "40000 / 45674 = 0.876 (49.27 s)\n",
      "45000 / 45674 = 0.985 (50.55 s)\n",
      "45674 / 45674 = 1.000 (50.60 s)\n",
      "Removing useless houses...\n",
      "Calculating closest houses...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "class House:\n",
    "    \"\"\"\n",
    "    An object that contains data for a single residential building.\n",
    "    Stores a list of addresses that correspond to this building.\n",
    "    The address list could have size 1 (if it's a single-family house) \n",
    "        or be very long (if it's an apartment)\n",
    "    \"\"\"\n",
    "    def __init__(self, footprint):\n",
    "        \"\"\"\n",
    "        Create a House object with a given footprint.\n",
    "        The list of addresses starts out empty - use addPlace to add an address\n",
    "         - footprint: MultiPolygon\n",
    "        \"\"\"\n",
    "        # footprint (MultiPolygon): house footprint (MultiPolygon)\n",
    "        self.footprint = footprint\n",
    "        # centroid (np.ndarray of shape (2,)): house centroid in the form [x,y] \n",
    "        self.centroid = footprint.centroid()\n",
    "        # numAddr (int): number of addresses corresponding to this house\n",
    "        self.numAddr = 0\n",
    "        # nClosest ([int]): contains a list of the nClosest_n closest houses\n",
    "        # nClosest_n (int): the size of nClosest\n",
    "        # The closest is always the house itself, so we initialize nClosest with [0]\n",
    "        # and nClosest_n with 1.\n",
    "        # Given a list of houses, this can be updated with House.setNClosest. \n",
    "        self.nClosest_n = 1\n",
    "        self.nClosest = [0.]\n",
    "        # addrs ({str}): the set of unique addresses that correspond to this house\n",
    "        # does NOT include subaddresses (like Apt 23)\n",
    "        self.addrs = set()\n",
    "        # tax_data (DataFrame): a dataframe including the tax frame rows\n",
    "        # for the addresses corresponding to this house\n",
    "        self.tax_data = pd.DataFrame(columns=tax_frame.columns)\n",
    "        # data_list ([Series]): list of dataframe rows added by self.addPlace\n",
    "        self.data_list = []\n",
    "        # features (np.ndarray with 1 dimension): features for the house\n",
    "        # Starts out with a single garbage feature (can be updated later by finalize_features)\n",
    "        self.features = np.random.rand(1) # features: starts out with garbage data\n",
    "    def addPlace(self,row):\n",
    "        \"\"\"\n",
    "        Adds a row (from addr_frame) to the list of addresses for this house\n",
    "        \"\"\"\n",
    "        addr = row['address']\n",
    "        self.numAddr += 1\n",
    "        self.data_list.append(row)\n",
    "        if addr not in self.addrs:\n",
    "            self.addrs.add(addr)\n",
    "            if row['taxes_found']:\n",
    "                self.tax_data.loc[len(self.tax_data)] = row[tax_frame.columns]\n",
    "    @staticmethod\n",
    "    def setNClosest(houses, nClosest_n=10):\n",
    "        \"\"\"\n",
    "        Given a list of houses, sets the nClosest and nClosest_n attribute for the houses\n",
    "        \"\"\"\n",
    "        house_cents = np.stack([h.centroid for h in houses],0)\n",
    "        for house_i,house in enumerate(houses):\n",
    "            dists = latlon.approx_dist(house_cents[house_i],house_cents)\n",
    "            dists.sort()\n",
    "            house.nClosest_n = nClosest_n\n",
    "            house.nClosest = dists[:house.nClosest_n]\n",
    "\n",
    "print(\"Creating houses...\")\n",
    "houses = [House(fp) for fp in house_polys]\n",
    "print(\"Putting addresses into houses...\")\n",
    "prog = progress.Progress(len(putted_indices),5000)\n",
    "for putted_i,putted in enumerate(putted_indices):\n",
    "    prog.update()\n",
    "    if putted == -1:\n",
    "        continue\n",
    "    houses[putted].addPlace(addr_frame.iloc[putted_i])\n",
    "\n",
    "print(\"Removing useless houses...\")\n",
    "houses = [h for h in houses if h.numAddr>0]\n",
    "\n",
    "print(\"Calculating closest houses...\")\n",
    "House.setNClosest(houses)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "structured-shopper",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list of feature names (there are 8 features)\n",
    "FEATURE_NAMES = [\n",
    "    'area',\n",
    "    'dist_closest',\n",
    "    'dist_closest2',\n",
    "    'num_addresses',\n",
    "    'tax_amount',\n",
    "    'land_value',\n",
    "    'building_value',\n",
    "    'land_value_per_area'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "damaged-ordinary",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalize_features(houses, num_reduced_features=2):\n",
    "    \"\"\"Given a list of houses, finalizes their 'features' attribute\n",
    "    relevant features:\n",
    "     - 0 | house area (house.footprint.totalArea)\n",
    "     - 1 | distance to closest house (house.nClosest[1])\n",
    "     - 2 | distance to 2nd closest house (house.nClosest[2])\n",
    "     - 3 | number of residential addresses (house.numAddr)\n",
    "     - 4 | average tax amount for addresses (tax_amount)\n",
    "     - 5 | average land value for addresses (land_value)\n",
    "     - 6 | average building value for addresses (building_value)\n",
    "     - 7 | land value per square unit (land_value/house_area)\n",
    "    \"\"\"\n",
    "    num_features = 8\n",
    "    features = np.zeros((len(houses),num_features))\n",
    "    # generate features\n",
    "    for house_i,house in enumerate(houses):\n",
    "        f_area = house.footprint.totalArea\n",
    "        f_dist1 = house.nClosest[1]\n",
    "        f_dist2 = house.nClosest[2]\n",
    "        f_numaddr = house.numAddr\n",
    "        if len(house.tax_data):\n",
    "            tdmean = house.tax_data.mean(0)\n",
    "        else:\n",
    "            tdmean = tax_average\n",
    "        def gen_tdmean_attr(attr):\n",
    "            return tdmean[attr] if tdmean[attr] != 0 else tax_average[attr]\n",
    "        f_tax_amount = gen_tdmean_attr('tax_amount')\n",
    "        f_land_value = gen_tdmean_attr('land_value')\n",
    "        f_building_value = gen_tdmean_attr('building_value')\n",
    "        f_sqfoot_value = f_land_value/f_area\n",
    "        features[house_i,:] = np.array([f_area,f_dist1,f_dist2,f_numaddr,\n",
    "                                        f_tax_amount,f_land_value,f_building_value,f_sqfoot_value])\n",
    "        for zz in range(8):\n",
    "            if features[house_i][zz] == 0:\n",
    "                print(house_i,zz)\n",
    "    # normalize features using log\n",
    "    features_log = np.log2(features)\n",
    "    features_final = features_log\n",
    "    # send features back to house objects\n",
    "    for house_i,house in enumerate(houses):\n",
    "        house.features = features_final[house_i,:]\n",
    "\n",
    "finalize_features(houses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "tight-cherry",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DISTANCE SUPERVISION MODEL\n",
    "This model attempts to learn weights for the 8 house features,\n",
    "by training a logistic regression classifier to attempt to classify between two houses being\n",
    "close together (distance less than DIST_MAX), or far apart (distance greater than DIST_MAX)\n",
    "The weights learned by this logistic regression are then used as weights for the 8 house features\n",
    "\"\"\"\n",
    "\n",
    "### calculate feature importance using distance supervision ###\n",
    "DIST_MAX = .3  # in km\n",
    "NUM_TRAIN = 5000  # this better be a multiple of 2\n",
    "\n",
    "# gather training data\n",
    "N_HOUSES = len(houses)\n",
    "NUM_TRAIN_EACH = NUM_TRAIN/2\n",
    "ds_close_points = []\n",
    "ds_far_points = []\n",
    "\n",
    "while len(ds_close_points)+len(ds_far_points) < NUM_TRAIN:\n",
    "    hi,hj = tuple(random.sample(range(N_HOUSES),2))\n",
    "    d = latlon.approx_dist(houses[hi].centroid, houses[hj].centroid)\n",
    "    datapoint = (houses[hi].features, houses[hj].features)\n",
    "    if d <= DIST_MAX and len(ds_close_points) < NUM_TRAIN/2:\n",
    "        ds_close_points.append(datapoint)\n",
    "    elif d > DIST_MAX and len(ds_far_points) < NUM_TRAIN/2:\n",
    "        ds_far_points.append(datapoint)\n",
    "\n",
    "def get_feature_vec(hf1, hf2):\n",
    "    \"\"\"given two house features, compute the distance feature to be used for distance supervision\n",
    "    hf1 (np.ndarray of size 8): house features for house 1\n",
    "    hf2 (np.ndarray of size 8): house features for house 2\n",
    "    \"\"\"\n",
    "    return np.abs(hf1-hf2)\n",
    "\n",
    "def stacked_feature_vecs(ds_points):\n",
    "    \"\"\"converts ds_close_points or ds_far_points into a stacked tuple of \n",
    "        logistic regression feature vectors\n",
    "    ds_points ([(np.ndarray, np.ndarray)]): either ds_close_points or ds_far_points\n",
    "    \"\"\"\n",
    "    return np.stack([get_feature_vec(*p) for p in ds_points])\n",
    "\n",
    "# training data for the logistic regression\n",
    "y_train = np.concatenate((\n",
    "    np.zeros(len(ds_close_points)),\n",
    "    np.ones(len(ds_far_points))\n",
    "))\n",
    "x_train = np.concatenate((\n",
    "    stacked_feature_vecs(ds_close_points),\n",
    "    stacked_feature_vecs(ds_far_points)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "banner-temple",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_model = linear_model.LogisticRegression(fit_intercept=True)\n",
    "ds_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "announced-celtic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.31096528  1.07109025  0.01828399 -0.07759281 -0.21611248  1.14433986\n",
      "   0.45912157  0.05385504]] [-1.60912928]\n"
     ]
    }
   ],
   "source": [
    "# print out some info about the logistic regression\n",
    "ds_model.predict_proba(x_train[:10])\n",
    "# ds_model.score(x_train, y_train)\n",
    "print(ds_model.coef_,ds_model.intercept_)\n",
    "# generic saved weights: [ 0.34041744, 0.92774432, 0.09131713, -0.10435152, -0.17135961, 0.98659969, 0.57859899, 0.05270441]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "august-perry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1055\n"
     ]
    }
   ],
   "source": [
    "# load the road regions (generated from road_region_creator.ipynb)\n",
    "road_poly_file = open('road_regions.json','r')\n",
    "road_polys = polygons.PolyList.import_json(road_poly_file)\n",
    "\n",
    "# create a polygon graph containing the road regions\n",
    "importlib.reload(polygongraph)\n",
    "house_cents = np.stack([h.centroid for h in houses],0)\n",
    "graph = polygongraph.PolygonGraph(road_polys, house_cents, houses)\n",
    "print(graph.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "desperate-waters",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(polygons)\n",
    "def get_features(houses):\n",
    "    \"\"\"gets a stacked ndarray of features for a list of houses\n",
    "     - houses: [House]\n",
    "    output: np.ndarray\n",
    "    \"\"\"\n",
    "    return np.stack([h.features for h in houses])\n",
    "\n",
    "def dist_features(houses1, houses2, explain=False):\n",
    "    \"\"\"gets the dissimilarity measure between two lists of houses,\n",
    "        to be used with AGNES\n",
    "     - houses1 ([House])\n",
    "     - houses2 ([House])\n",
    "     - explain: if true, instead of returning a dissimilarity, \n",
    "         returns a string explaining why the dissimilarity is calculated to what it is\n",
    "    \"\"\"\n",
    "    feat1 = get_features(houses1)\n",
    "    feat2 = get_features(houses2)\n",
    "    f1mean = feat1.mean(0)\n",
    "    f2mean = feat2.mean(0)\n",
    "    ds_fvec = get_feature_vec(f1mean, f2mean)\n",
    "    \n",
    "    # use the weights learned from the distance supervision model\n",
    "    fweights = ds_model.coef_[0].copy()\n",
    "    # weights below 0 are set to 0 (because negative weights don't make sense)\n",
    "    fweights[fweights<0] = 0\n",
    "    \n",
    "    # explain the result\n",
    "    if explain:\n",
    "        v = ds_fvec*fweights\n",
    "        n_feats = len(FEATURE_NAMES)\n",
    "        res = []\n",
    "        for i in range(n_feats):\n",
    "            if fweights[i] != 0:\n",
    "                res.append((v[i],FEATURE_NAMES[i]))\n",
    "        res.sort(reverse=True)\n",
    "        return ', '.join([t[1]+' '+str(t[0]) for t in res])\n",
    "        \n",
    "    # return the weighted sum\n",
    "    return np.dot(ds_fvec, fweights)\n",
    "    \n",
    "\n",
    "def dist_func(node1, node2, explain=False):\n",
    "    \"\"\"Returns the dissimilarity measure between two nodes in a PolygonGraph\n",
    "     - node1 (PolygonNode)\n",
    "     - node2 (PolygonNode)\n",
    "     - explain: whether or not to return a string explaning the result\n",
    "    \"\"\"\n",
    "    # get the dissimilarity based on data features\n",
    "    dist_f = dist_features(node1.data, node2.data, explain)\n",
    "    # get the shared perimeter proportion between the 2 polygons\n",
    "    perim_f = polygons.MultiPolygon.shared_perimeters(node1.poly,node2.poly) / min(node1.poly.perimeter(),node2.poly.perimeter())\n",
    "    unperim_f = 1-perim_f\n",
    "    if explain:\n",
    "        if perim_f == 0:\n",
    "            return 'These polygons don\\'t even share an edge...'\n",
    "        return 'Feature impact: %s\\nPerimeter Modifier: %f' % (dist_f, unperim_f)\n",
    "    return dist_f * (1+unperim_f)\n",
    "\n",
    "# run AGNES\n",
    "graph.agnes_cluster(dist_func, 1)\n",
    "# number of clusters at the end\n",
    "print(graph.agnes_min_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "inappropriate-arabic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base polygons (1055): 0-1054\n",
      "Merged polygons (696): 1055-1750\n",
      "Active polygons (359)\n"
     ]
    }
   ],
   "source": [
    "# set the number of clusters in the final result (based on maximum dissimilarity)\n",
    "graph.agnes_set_num_clusters(max_dist=1)\n",
    "print(graph.agnes_get_stats())\n",
    "\n",
    "# store AGNES results into a js file\n",
    "agnes_res = graph.agnes_get_result_polygons()\n",
    "agnes_labels = graph.agnes_get_labelled_centroids()\n",
    "dumper = jsdump.Dumper('agnes_road_regions.js')\n",
    "dumper.dump('agnes_road_regions', polygons.PolyList.to_vertex_lists(agnes_res))\n",
    "dumper.dump('agnes_centroid_labels', agnes_labels)\n",
    "dumper.done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "separate-addition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1536,1308) -> 1598\n",
      "1536 <- (54,1535)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# an example of using agnes_explain\n",
    "print(graph.agnes_explain(1536))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "removable-traffic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature impact: dist_closest 0.31291258817612977, land_value 0.28166119813799795, building_value 0.09269085484718631, area 0.031519535586215106, dist_closest2 0.00827999724864551, land_value_per_area 0.00779680472829889\n",
      "Perimeter Modifier: 0.653487\n"
     ]
    }
   ],
   "source": [
    "# an example of using agnes_explain_pair\n",
    "print(graph.agnes_explain_pair(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adequate-custom",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this allows visualizing a colormap of specific features on the generated Google maps\n",
    "importlib.reload(FloatColorMapper)\n",
    "def gen_floatcolors_json():\n",
    "    floatcolors_json = {}\n",
    "    house_cents = [h.centroid for h in houses]\n",
    "    for fi,fname in enumerate(FEATURE_NAMES):\n",
    "        feats = [h.features[fi] for h in houses]\n",
    "        floatcolors_json[fname] = FloatColorMapper.genJSON(\n",
    "            house_cents, feats,\n",
    "            norm_func=FloatColorMapper.normalize_minmax\n",
    "        )\n",
    "    return floatcolors_json\n",
    "floatcolors_json = gen_floatcolors_json()\n",
    "dumper = jsdump.Dumper('feature_color_map.js')\n",
    "dumper.dump('feature_color_map', floatcolors_json)\n",
    "dumper.done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "available-vault",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agnes address list generator\n",
    "# json output: [id: {addrs: [...], edges: [...]}]\n",
    "# addresses are CompleteAddress\n",
    "agnes_json = {}\n",
    "for node_i in graph.agnes_get_result_node_idx():\n",
    "    addrs = []\n",
    "    for node_data in graph.agnes_nodes[node_i].data:\n",
    "        addrs += [row['CompleteAddress'] for row in node_data.data_list]\n",
    "    edges = [str(j) for j in graph.agnes_edges_for_node(node_i)]\n",
    "    agnes_json[node_i] = {'addrs': addrs, 'edges': edges}\n",
    "\n",
    "with open('agnes_result.json', 'w') as output:\n",
    "    json.dump(agnes_json, output, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agricultural-senior",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
